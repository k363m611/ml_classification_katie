{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c897b2e-bb79-49ed-b1db-23427d3e57e9",
   "metadata": {},
   "source": [
    "# Classification Analysis: Titanic Dataset\n",
    "**Name:** Katie  \n",
    "**Date:** April 6, 2025  \n",
    "\n",
    "## Introduction  \n",
    "The objective of this project is to build a machine learning model to predict survival on the Titanic. The dataset contains demographic and travel-related features, and the target variable is whether or not a passenger survived. We will explore the data, engineer features, train classification models, and compare their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a0906a-dd62-4607-8197-d645fe103801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training dataset\n",
    "df = pd.read_csv(\"data/train.csv\")\n",
    "\n",
    "# Display first 10 rows\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd898b7-4b0c-4d8e-a844-496b130ef60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "df.isnull().sum()\n",
    "\n",
    "# Summary statistics\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3b1cf1-b28c-4b33-bddf-bf661f3b1c34",
   "metadata": {},
   "source": [
    "### Reflection 1:\n",
    "The dataset contains a mix of categorical (e.g., `Sex`, `Embarked`) and numerical (e.g., `Age`, `Fare`) features. There are missing values in the `Age`, `Cabin`, and `Embarked` columns. The `Cabin` column has a lot of missing values and may need to be dropped. Overall, the dataset is relatively clean but needs some preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a7b70d-27f6-452b-8278-594aff1bf65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set plot style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Histogram of Age\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.histplot(df['Age'].dropna(), kde=True)\n",
    "plt.title(\"Distribution of Age\")\n",
    "plt.show()\n",
    "\n",
    "# Boxplot of Fare\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.boxplot(x='Fare', data=df)\n",
    "plt.title(\"Boxplot of Fare\")\n",
    "plt.show()\n",
    "\n",
    "# Count plot for Survived\n",
    "sns.countplot(x='Survived', data=df)\n",
    "plt.title(\"Survival Count (Target Variable)\")\n",
    "plt.xticks([0, 1], ['Did Not Survive', 'Survived'])\n",
    "plt.show()\n",
    "\n",
    "# Count plot for Pclass\n",
    "sns.countplot(x='Pclass', data=df)\n",
    "plt.title(\"Passenger Class Distribution\")\n",
    "plt.show()\n",
    "\n",
    "# Count plot for Sex\n",
    "sns.countplot(x='Sex', data=df)\n",
    "plt.title(\"Passenger Sex Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd400716-06d6-457c-9c88-6f3ed5b13e53",
   "metadata": {},
   "source": [
    "### Reflection 2:\n",
    "The Age column has a fairly normal distribution but contains some missing values. The Fare column has a long tail with some high outliers. There is a class imbalance in the target variable: more people died than survived. Most passengers are in 3rd class, and more males than females are aboard. These patterns will be important during feature selection and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07988bfb-34a7-4526-87c8-399c7a7f753b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check again which columns have missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454de3cf-b1b3-4afa-8498-6f110bdf4745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Cabin (too many missing values)\n",
    "df.drop('Cabin', axis=1, inplace=True)\n",
    "\n",
    "# Fill missing Age values with median\n",
    "df['Age'].fillna(df['Age'].median(), inplace=True)\n",
    "\n",
    "# Fill missing Embarked values with mode\n",
    "df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "# Double-check missing values now\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ec59ef-d40a-4879-b3fb-0364eba70aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Sex to numerical (male=0, female=1)\n",
    "df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n",
    "\n",
    "# One-hot encode Embarked (C, Q, S)\n",
    "df = pd.get_dummies(df, columns=['Embarked'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135c53cc-0c34-4f23-80e0-1dbaa0923a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df[['Age', 'Fare']] = scaler.fit_transform(df[['Age', 'Fare']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72bf7bc-0758-4664-a7c7-f5596a4642a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new feature\n",
    "df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "\n",
    "# Drop unused columns\n",
    "df.drop(['Name', 'Ticket', 'PassengerId'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a83bc6-e06c-42cf-bdda-b7cf9a11edf4",
   "metadata": {},
   "source": [
    "### Reflection 2 (continued):\n",
    "I dropped the Cabin column due to a large number of missing values. Age was filled with the median and Embarked with the mode. I converted Sex to numerical values and applied one-hot encoding to Embarked. Finally, I scaled Age and Fare to normalize their ranges. These steps help clean the dataset and prepare it for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fefa1fc-6619-4202-b847-c1a35b3ac5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Family size = siblings/spouse + parents/children + self\n",
    "df['FamilySize'] = df['SibSp'] + df['Parch'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2f97f1-1d2d-46f0-85f3-e586fbb62b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Name', 'Ticket', 'PassengerId'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2026e41-03c6-4aa6-a874-1d8cdf784115",
   "metadata": {},
   "source": [
    "I created a new feature called `FamilySize` by combining `SibSp`, `Parch`, and 1 (for the individual). This could help capture whether traveling in a group affected survival. I also dropped `Name`, `Ticket`, and `PassengerId` since they aren’t useful predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2afbde-9900-4b1d-8a8c-15037e6b26f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target variable\n",
    "y = df['Survived']\n",
    "\n",
    "# Define feature variables\n",
    "X = df.drop('Survived', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f4624b-f552-4818-ac1d-894c83b99939",
   "metadata": {},
   "source": [
    "### Reflection 3:\n",
    "I selected all cleaned and engineered features (excluding the target `Survived`) for `X`. These include `Pclass`, `Sex`, `Age`, `Fare`, `SibSp`, `Parch`, `FamilySize`, and the one-hot encoded `Embarked` columns. These features provide information about passenger demographics, socioeconomic status, and group size — all of which may influence survival. I believe this set captures a well-rounded view of the passengers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5345707-1f9d-4040-b636-4af61693a7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y  # stratify keeps class balance\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc6f698-9e54-4d20-b446-c03620352fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train logistic regression\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928e94fd-4213-457d-ad4c-3fcaf9417ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfe3d37-4821-4b2b-8235-1393b7bee3ba",
   "metadata": {},
   "source": [
    "### Reflection 4:\n",
    "The logistic regression model performed reasonably well, with accuracy around 80%. Precision and recall varied slightly between classes. It seems the model is slightly better at predicting non-survivors than survivors, which might reflect the class imbalance. Overall, it's a solid baseline model for this classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a315ce-4ede-4803-9f2f-f51a1f2d783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "rf_preds = rf_model.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, rf_preds))\n",
    "print(classification_report(y_test, rf_preds))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, rf_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df03f91-20f8-485b-845c-f8ce3596be77",
   "metadata": {},
   "source": [
    "### Reflection 5:\n",
    "The Random Forest model performed better than logistic regression, with improved recall and accuracy. This is likely due to its ability to handle complex feature interactions. It’s a good fit for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c534f35-2944-4124-8a2d-db65c8987d42",
   "metadata": {},
   "source": [
    "## Final Thoughts & Insights\n",
    "\n",
    "### 6.1 Summary of Findings:\n",
    "The models performed reasonably well, with Random Forest outperforming logistic regression. Key predictors were `Sex`, `Pclass`, and `Fare`.\n",
    "\n",
    "### 6.2 Challenges Faced:\n",
    "Handling missing values, selecting features, and interpreting evaluation metrics were challenging but educational.\n",
    "\n",
    "### 6.3 What I'd Do With More Time:\n",
    "I’d try hyperparameter tuning, cross-validation, and more advanced models like XGBoost.\n",
    "\n",
    "### Reflection 6:\n",
    "This project gave me hands-on practice with the full ML pipeline — from raw data to models and reflection. It also reinforced how important data cleaning and thoughtful modeling choices are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3143f1d-6c04-438e-aa36-f0f9a217dc74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
